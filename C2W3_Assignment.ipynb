{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurater/Certificado-Profissional-DeepLearning.AI-TensorFlow-Developer/blob/main/C2W3_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8cj-HBNoEZy"
      },
      "source": [
        "# Week 3: Transfer Learning\n",
        "\n",
        "Welcome to this assignment! This week, you are going to use a technique called `Transfer Learning` in which you utilize an already trained network to help you solve a similar problem to the one it was originally trained to solve.\n",
        "\n",
        "Let's get started!"
      ],
      "id": "f8cj-HBNoEZy"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ],
      "id": "lbFmQdsZs5eW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPvtLK1GyUWr"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "For this assignment, you will use the `Horse or Human dataset`, which contains images of horses and humans. \n",
        "\n",
        "Download the `training` and `validation` sets by running the cell below:"
      ],
      "id": "RPvtLK1GyUWr"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dIeTNcPEo79J",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get the Horse or Human training dataset\n",
        "!wget -q -P /content/ https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human validation dataset\n",
        "!wget -q -P /content/ https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\n",
        "\n",
        "test_local_zip = './horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(test_local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "\n",
        "val_local_zip = './validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(val_local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "\n",
        "zip_ref.close()"
      ],
      "id": "dIeTNcPEo79J"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4OMDxYS6tmv"
      },
      "source": [
        "This dataset already has an structure that is compatible with Keras' `flow_from_directory` so you don't need to move the images into subdirectories as you did in the previous assignments. However, it is still a good idea to save the paths of the images so you can use them later on:"
      ],
      "id": "x4OMDxYS6tmv"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lHRrmo5CpEw_",
        "lines_to_next_cell": 2,
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c456097-6f58-43ee-869a-832d07d11e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 500 images of horses for training.\n",
            "\n",
            "There are 527 images of humans for training.\n",
            "\n",
            "There are 128 images of horses for validation.\n",
            "\n",
            "There are 128 images of humans for validation.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the training and validation base directories\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Directory with training horse pictures\n",
        "train_horses_dir = os.path.join(train_dir, 'horses')\n",
        "# Directory with training humans pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')\n",
        "# Directory with validation horse pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
        "# Directory with validation human pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
        "\n",
        "# Check the number of images for each class and set\n",
        "print(f\"There are {len(os.listdir(train_horses_dir))} images of horses for training.\\n\")\n",
        "print(f\"There are {len(os.listdir(train_humans_dir))} images of humans for training.\\n\")\n",
        "print(f\"There are {len(os.listdir(validation_horses_dir))} images of horses for validation.\\n\")\n",
        "print(f\"There are {len(os.listdir(validation_humans_dir))} images of humans for validation.\\n\")"
      ],
      "id": "lHRrmo5CpEw_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G5hXBB57c78"
      },
      "source": [
        "Now take a look at a sample image of each one of the classes:"
      ],
      "id": "1G5hXBB57c78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgbMs7p0qSKr",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "print(\"Sample horse image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(train_horses_dir, os.listdir(train_horses_dir)[0])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample human image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(train_humans_dir, os.listdir(train_humans_dir)[0])}\"))\n",
        "plt.show()"
      ],
      "id": "HgbMs7p0qSKr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBnbnY0c8Zd0"
      },
      "source": [
        "`matplotlib` makes it easy to see that these images have a resolution of 300x300 and are colored, but you can double check this by using the code below:"
      ],
      "id": "LBnbnY0c8Zd0"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4lIGjHC5pxua",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f4a7d6-baee-45fa-c49b-36f2cdf0340f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Each image has shape: (300, 300, 3)\n"
          ]
        }
      ],
      "source": [
        "# Load the first example of a horse\n",
        "sample_image  = load_img(f\"{os.path.join(train_horses_dir, os.listdir(train_horses_dir)[0])}\")\n",
        "\n",
        "# Convert the image into its numpy array representation\n",
        "sample_array = img_to_array(sample_image)\n",
        "\n",
        "print(f\"Each image has shape: {sample_array.shape}\")"
      ],
      "id": "4lIGjHC5pxua"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fYwAYyd8zEm"
      },
      "source": [
        "As expected, the sample image has a resolution of 300x300 and the last dimension is used for each one of the RGB channels to represent color."
      ],
      "id": "4fYwAYyd8zEm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HcE1TSqNRY2"
      },
      "source": [
        "## Training and Validation Generators\n",
        "\n",
        "Now that you know the images you are dealing with, it is time for you to code the generators that will fed these images to your Network. For this, complete the `train_val_generators` function below:\n",
        "\n",
        "**Important Note:** The images have a resolution of 300x300 but the `flow_from_directory` method you will use allows you to set a target resolution. In this case, **set a `target_size` of (150, 150)**. This will heavily lower the number of trainable parameters in your final network, yielding much quicker training times without compromising the accuracy!"
      ],
      "id": "6HcE1TSqNRY2"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "code",
        "id": "AX5Q3NL_FXMT",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "  \n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "    \n",
        "  Returns:\n",
        "    train_generator, validation_generator: tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class \n",
        "  # Don't forget to normalize pixel values and set arguments to augment the images \n",
        "  train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=32, \n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  # Remember that validation data should not be augmented\n",
        "  validation_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=32, \n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator\n"
      ],
      "id": "AX5Q3NL_FXMT"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8FLUUqMKFwVR",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857b0028-bf93-4635-8895-c0f1248ebb90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(train_dir, validation_dir)"
      ],
      "id": "8FLUUqMKFwVR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszKWhunQaj4"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Found 1027 images belonging to 2 classes.\n",
        "Found 256 images belonging to 2 classes.\n",
        "```"
      ],
      "id": "TszKWhunQaj4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izx51Ju1rXwd"
      },
      "source": [
        "## Transfer learning - Create the pre-trained model\n",
        "\n",
        "Download the `inception V3` weights into the `/tmp/` directory:"
      ],
      "id": "Izx51Ju1rXwd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lEzPAqxrPcU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "id": "-lEzPAqxrPcU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zlXNulm9USZ"
      },
      "source": [
        "Now load the `InceptionV3` model and save the path to the weights you just downloaded:"
      ],
      "id": "_zlXNulm9USZ"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zfmRpsMf7E3-",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "id": "zfmRpsMf7E3-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPQb0PkT9_3w"
      },
      "source": [
        "Complete the `create_pre_trained_model` function below. You should specify the correct `input_shape` for the model (remember that you set a new resolution for the images instead of the native 300x300) and make all of the layers non-trainable:"
      ],
      "id": "ZPQb0PkT9_3w"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "code",
        "id": "x2JnQ6m8r5oe",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: create_pre_trained_model\n",
        "def create_pre_trained_model(local_weights_file):\n",
        "  \"\"\"\n",
        "  Initializes an InceptionV3 model.\n",
        "  \n",
        "  Args:\n",
        "    local_weights_file (string): path pointing to a pretrained weights H5 file\n",
        "    \n",
        "  Returns:\n",
        "    pre_trained_model: the initialized InceptionV3 model\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "  pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                  include_top = False, \n",
        "                                  weights = None) \n",
        "\n",
        "  pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "  # Make all the layers in the pre-trained model non-trainable\n",
        "  for layer in pre_trained_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  return pre_trained_model\n",
        "  "
      ],
      "id": "x2JnQ6m8r5oe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phE00SCr-RCT"
      },
      "source": [
        "Check that everything went well by comparing the last few rows of the model summary to the expected output:"
      ],
      "id": "phE00SCr-RCT"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ve7eh9iztT4q",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc89272-58b5-4312-f299-adefc0cd5be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "pre_trained_model = create_pre_trained_model(local_weights_file)\n",
        "\n",
        "# Print the model summary\n",
        "pre_trained_model.summary()"
      ],
      "id": "ve7eh9iztT4q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cAY2gQytr0-"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "__________________________________________________________________________________________________\n",
        "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "__________________________________________________________________________________________________\n",
        "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "                                                                activation_276[0][0]             \n",
        "__________________________________________________________________________________________________\n",
        "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "                                                                activation_280[0][0]             \n",
        "__________________________________________________________________________________________________\n",
        "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "__________________________________________________________________________________________________\n",
        "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "                                                                mixed9_1[0][0]                   \n",
        "                                                                concatenate_5[0][0]              \n",
        "                                                                activation_281[0][0]             \n",
        "==================================================================================================\n",
        "Total params: 21,802,784\n",
        "Trainable params: 0\n",
        "Non-trainable params: 21,802,784\n",
        "\n",
        "\n",
        "```"
      ],
      "id": "4cAY2gQytr0-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRHkV9jo-hkh"
      },
      "source": [
        "To check that all the layers in the model were set to be non-trainable, you can also run the cell below:"
      ],
      "id": "MRHkV9jo-hkh"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VASOaB8xDbhU",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7f55cc-d4bd-47f0-ba94-e471d03843b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 21,802,784 total parameters in this model.\n",
            "There are 0 trainable parameters in this model.\n"
          ]
        }
      ],
      "source": [
        "total_params = pre_trained_model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in pre_trained_model.trainable_weights])\n",
        "\n",
        "print(f\"There are {total_params:,} total parameters in this model.\")\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
      ],
      "id": "VASOaB8xDbhU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRioO7FH5a8I"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "There are 21,802,784 total parameters in this model.\n",
        "There are 0 trainable parameters in this model.\n",
        "```"
      ],
      "id": "mRioO7FH5a8I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFtwDyKj-4GR"
      },
      "source": [
        "## Creating callbacks for later\n",
        "\n",
        "You have already worked with callbacks in the first course of this specialization so the callback to stop training once an accuracy of 99.9% is reached, is provided for you:"
      ],
      "id": "dFtwDyKj-4GR"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SeVjZD2o7gWS",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "id": "SeVjZD2o7gWS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHZnFl-5_p3a"
      },
      "source": [
        "## Pipelining the pre-trained model with your own\n",
        "\n",
        "Now that the pre-trained model is ready, you need to \"glue\" it to your own model to solve the task at hand.\n",
        "\n",
        "For this you will need the last output of the pre-trained model, since this will be the input for your own. Complete the `output_of_last_layer` function below.\n",
        "\n",
        "**Note:** For grading purposes use the `mixed7` layer as the last layer of the pre-trained model. However, after submitting feel free to come back here and play around with this."
      ],
      "id": "lHZnFl-5_p3a"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: output_of_last_layer\n",
        "def output_of_last_layer(pre_trained_model):\n",
        "  \"\"\"\n",
        "  Gets the last layer output of a model\n",
        "  \n",
        "  Args:\n",
        "    pre_trained_model (tf.keras Model): model to get the last layer output from\n",
        "    \n",
        "  Returns:\n",
        "    last_output: output of the model's last layer \n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "  last_desired_layer = pre_trained_model.get_layer('mixed7')\n",
        "  print('last layer output shape: ', last_desired_layer.output_shape)\n",
        "  last_output = last_desired_layer.output\n",
        "  print('last layer output: ', last_output)\n",
        "  ### END CODE HERE\n",
        "\n",
        "  return last_output\n"
      ],
      "id": "CFsUlwdfs_wg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13AEzKG2A6_J"
      },
      "source": [
        "Check that everything works as expected:"
      ],
      "id": "13AEzKG2A6_J"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zOJPUtMN6PHo",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24364452-4efe-43de-8aff-079a521ae26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n",
            "last layer output:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 768), dtype=tf.float32, name=None), name='mixed7/concat:0', description=\"created by layer 'mixed7'\")\n"
          ]
        }
      ],
      "source": [
        "last_output = output_of_last_layer(pre_trained_model)"
      ],
      "id": "zOJPUtMN6PHo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqIWKZ_h7CuY"
      },
      "source": [
        "**Expected Output (if `mixed7` layer was used):**\n",
        "```\n",
        "last layer output shape:  (None, 7, 7, 768)\n",
        "last layer output:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 768), dtype=tf.float32, name=None), name='mixed7/concat:0', description=\"created by layer 'mixed7'\")\n",
        "```"
      ],
      "id": "XqIWKZ_h7CuY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rp-J6JuwJTq"
      },
      "source": [
        "Now you will create the final model by adding some additional layers on top of the pre-trained model.\n",
        "\n",
        "Complete the `create_final_model` function below. You will need to use Tensorflow's [Functional API](https://www.tensorflow.org/guide/keras/functional) for this since the pretrained model has been created using it. \n",
        "\n",
        "Let's double check this first:"
      ],
      "id": "0Rp-J6JuwJTq"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cKQknB4j7K9y",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4d4759-9404-413a-cb63-dc6d5233a2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The pretrained model has type: <class 'keras.engine.functional.Functional'>\n"
          ]
        }
      ],
      "source": [
        "# Print the type of the pre-trained model\n",
        "print(f\"The pretrained model has type: {type(pre_trained_model)}\")"
      ],
      "id": "cKQknB4j7K9y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt7AU7jP7LW9"
      },
      "source": [
        "To create the final model, you will use Keras' Model class by defining the appropriate inputs and outputs as described in the first way to instantiate a Model in the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/Model).\n",
        "\n",
        "Note that you can get the input from any existing model by using its `input` attribute and by using the Funcional API you can use the last layer directly as output when creating the final model."
      ],
      "id": "Kt7AU7jP7LW9"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "code",
        "id": "BMXb913pbvFg",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: create_final_model\n",
        "def create_final_model(pre_trained_model, last_output):\n",
        "  \"\"\"\n",
        "  Appends a custom model to a pre-trained model\n",
        "  \n",
        "  Args:\n",
        "    pre_trained_model (tf.keras Model): model that will accept the train/test inputs\n",
        "    last_output (tensor): last layer output of the pre-trained model\n",
        "    \n",
        "  Returns:\n",
        "    model: the combined model\n",
        "  \"\"\"\n",
        "  # Flatten the output layer to 1 dimension\n",
        "  x = layers.Flatten()(last_output)\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
        "  x = layers.Dense(1024, activation='relu')(x)\n",
        "  # Add a dropout rate of 0.2\n",
        "  x = layers.Dropout(0.2)(x)  \n",
        "  # Add a final sigmoid layer for classification\n",
        "  x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "  # Create the complete model by using the Model class\n",
        "  model = Model(inputs=pre_trained_model.input, outputs=x)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "                loss =  'binary_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  ### END CODE HERE\n",
        "  \n",
        "  return model\n"
      ],
      "id": "BMXb913pbvFg"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cL6ga5Z1783H",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf82377-9a01-4fe4-9d52-b1510d91d28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 47,512,481 total parameters in this model.\n",
            "There are 38,537,217 trainable parameters in this model.\n"
          ]
        }
      ],
      "source": [
        "# Save your model in a variable\n",
        "model = create_final_model(pre_trained_model, last_output)\n",
        "\n",
        "# Inspect parameters\n",
        "total_params = model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])\n",
        "\n",
        "print(f\"There are {total_params:,} total parameters in this model.\")\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
      ],
      "id": "cL6ga5Z1783H"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4d3zlcQDrvm"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "There are 47,512,481 total parameters in this model.\n",
        "There are 38,537,217 trainable parameters in this model.\n",
        "```"
      ],
      "id": "J4d3zlcQDrvm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eqwHj5xEBZ7"
      },
      "source": [
        "Wow, that is a lot of parameters!\n",
        "\n",
        "After submitting your assignment later, try re-running this notebook but use the original resolution of 300x300, you will be surprised to see how many more parameters are for that case.\n",
        "\n",
        "Now train the model:"
      ],
      "id": "_eqwHj5xEBZ7"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Blhq2MAUeyGA",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c4aa0e-01f0-4db6-845b-a7cfed95bc7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "33/33 [==============================] - 12s 367ms/step - loss: 0.0051 - accuracy: 0.9971 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 0.0091 - val_accuracy: 0.9961\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990    \n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "33/33 [==============================] - 13s 380ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0936 - val_accuracy: 0.9805\n"
          ]
        }
      ],
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take a few epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data = validation_generator,\n",
        "                    epochs = 100,\n",
        "                    verbose = 1,\n",
        "                    callbacks=callbacks)"
      ],
      "id": "Blhq2MAUeyGA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y94djl4t0sK5"
      },
      "source": [
        "The training should have stopped after less than 10 epochs and it should have reached an accuracy over 99,9% (firing the callback). This happened so quickly because of the pre-trained model you used, which already contained information to classify humans from horses. Really cool!\n",
        "\n",
        "Now take a quick look at the training and validation accuracies for each epoch of training:"
      ],
      "id": "Y94djl4t0sK5"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "058d2016-bab6-41ee-94e5-4f5b7fe1cc25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the training and validation accuracies for each epoch\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "id": "C2Fp6Se9rKuL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-4-4i9U1a0s"
      },
      "source": [
        "You will need to submit this notebook for grading. To download it, click on the `File` tab in the upper left corner of the screen then click on `Download` -> `Download .ipynb`. You can name it anything you want as long as it is a valid `.ipynb` (jupyter notebook) file."
      ],
      "id": "g-4-4i9U1a0s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w54-pbB1W9r"
      },
      "source": [
        "**Congratulations on finishing this week's assignment!**\n",
        "\n",
        "You have successfully implemented a convolutional neural network that leverages a pre-trained network to help you solve the problem of classifying humans from horses.\n",
        "\n",
        "**Keep it up!**"
      ],
      "id": "7w54-pbB1W9r"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "C2W3_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}